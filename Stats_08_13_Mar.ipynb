{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17f8de3b-bf5f-4a32-a1ed-f6194296f855",
   "metadata": {},
   "source": [
    "## Statistics Advance Assignment - 6\n",
    "***By Shahequa Modabbera***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb66d06-5000-41ae-b3b0-e8523e1e8eb6",
   "metadata": {},
   "source": [
    "### Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact the validity of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562a6cfb-ef61-4bd6-bab7-fb4fea56ce60",
   "metadata": {},
   "source": [
    "Ans) ANOVA (Analysis of Variance) is a statistical method used to compare the means of two or more groups. ANOVA assumes the following:\n",
    "\n",
    "1. Independence: Each observation within a group is independent of every other observation in that group.\n",
    "2. Normality: The response variable is normally distributed in each group.\n",
    "3. Homogeneity of variance: The variances of the response variable in each group are equal.\n",
    "\n",
    "Violations of these assumptions can impact the validity of the ANOVA results. For example:\n",
    "\n",
    "1. Independence violation: If observations within a group are not independent, the sample size within each group may be too small or the groups may be too similar or too different. For example, if a study is conducted on a married couple, then the observations within the couple are not independent.\n",
    "2. Normality violation: If the response variable is not normally distributed within each group, the ANOVA test may not be valid. This can occur when the sample size is too small or the data has outliers. For example, if a study measures the intelligence level of people but the sample size is too small or there are outliers, the data may not be normally distributed.\n",
    "3. Homogeneity of variance violation: If the variances of the response variable are not equal across the groups, then the ANOVA test may not be valid. This can occur when the sample sizes are unequal or the data have outliers. For example, if a study is conducted on the salaries of employees in different departments, but the number of employees in each department is not equal, then the variances may not be equal.\n",
    "\n",
    "It is important to check these assumptions before conducting an ANOVA test to ensure the validity of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d5116b-7922-4a82-b79c-c3dc5cefddce",
   "metadata": {},
   "source": [
    "### Q2. What are the three types of ANOVA, and in what situations would each be used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d125411-9e92-4077-b140-8b9e498e6f86",
   "metadata": {},
   "source": [
    "Ans) There are three main types of ANOVA:\n",
    "\n",
    "1. One-Way ANOVA: This is used when there is only one independent variable and one dependent variable. It is used to compare the means of three or more groups.\n",
    "\n",
    "2. Two-Way ANOVA: This is used when there are two independent variables and one dependent variable. It is used to determine the main effects and interactions between the two independent variables.\n",
    "\n",
    "3. MANOVA (Multivariate Analysis of Variance): This is used when there are multiple dependent variables and one or more independent variables. It is used to determine if there are differences between groups across multiple dependent variables.\n",
    "\n",
    "The choice of ANOVA type depends on the research question, study design, and the number of independent variables and dependent variables involved. One-Way ANOVA is the most commonly used type, as it is useful for comparing the means of multiple groups. Two-Way ANOVA is useful for examining the effects of two independent variables on a dependent variable, and can also identify interactions between the independent variables. MANOVA is useful for examining differences between groups across multiple dependent variables, and can provide more comprehensive results than a series of one-way ANOVAs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003c3840-553a-45dc-a4cf-a1df074803e7",
   "metadata": {},
   "source": [
    "### Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1897347d-8ac7-4124-bc59-2c1c1f0d24f1",
   "metadata": {},
   "source": [
    "Ans) The partitioning of variance in ANOVA refers to the process of breaking down the total variation in the data into different sources of variation, which are then used to estimate the statistical significance of the factors being analyzed. The total variation in the data is divided into two components: systematic variation and random variation. Systematic variation is due to the factors being studied, such as treatment groups or levels of a predictor variable, while random variation is due to chance factors that are not controlled or measured.\n",
    "\n",
    "By partitioning the variance, ANOVA allows researchers to determine the extent to which the variation in the outcome variable is due to the factors being studied versus random variation. This is important because it helps to identify the most significant sources of variation, which can then be used to explain and predict the outcome variable. It also enables researchers to test the statistical significance of each factor, which is necessary for making valid conclusions about the relationship between the factors and the outcome variable. Overall, understanding the partitioning of variance in ANOVA is critical for accurately interpreting the results and drawing valid conclusions from the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e9b53a-5a13-4ef3-8f9a-c3584eea1b42",
   "metadata": {},
   "source": [
    "### Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual sum of squares (SSR) in a one-way ANOVA using Python?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91be8cfa-3c02-4380-a78a-2910b3270de4",
   "metadata": {},
   "source": [
    "Ans) To calculate the total sum of squares (SST), explained sum of squares (SSE), and residual sum of squares (SSR) in a one-way ANOVA using Python, we can use the `ols()` function from the `statsmodels` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21e4d8e2-741d-4a21-9055-b4b2eff1f09e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SST: 82.22222222222221\n",
      "SSE: 14.666666666666668\n",
      "SSR: 67.55555555555554\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# create a DataFrame with the data\n",
    "data = {'group': ['A', 'A', 'A', 'B', 'B', 'B', 'C', 'C', 'C'],\n",
    "        'value': [10, 12, 14, 8, 9, 11, 15, 16, 17]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# fit the ANOVA model\n",
    "model = ols('value ~ group', data=df).fit()\n",
    "\n",
    "# calculate the SST, SSE, and SSR\n",
    "SST = sum((df['value'] - df['value'].mean())**2)\n",
    "SSE = sum(model.resid**2)\n",
    "SSR = SST - SSE\n",
    "\n",
    "print('SST:', SST)\n",
    "print('SSE:', SSE)\n",
    "print('SSR:', SSR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8238fc7-8088-44b4-909d-7fc8cff4561c",
   "metadata": {},
   "source": [
    "In this example, we create a DataFrame with the data and fit an ANOVA model using the `ols()` function. Then we calculate the SST, SSE, and SSR by using the `sum()` function on the squared deviations of the values from the mean for SST, the residuals for SSE, and subtracting SSE from SST for SSR."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e36ba78-0f82-4d4a-b0e8-e8ff39824594",
   "metadata": {},
   "source": [
    "### Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99c8815-7d4a-4add-83d4-4d63bed8bb60",
   "metadata": {},
   "source": [
    "Ans) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee34127-df02-458c-bd66-2541d62ab1a3",
   "metadata": {},
   "source": [
    "### Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02. What can you conclude about the differences between the groups, and how would you interpret these results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4ef452-968b-4526-b182-a48bf9298bd7",
   "metadata": {},
   "source": [
    "Ans) The obtained F-statistic of 5.23 and the corresponding p-value of 0.02 indicate that there is a statistically significant difference between the groups. This means that the means of at least two of the groups are different from each other.\n",
    "\n",
    "To further interpret these results, you can also look at the effect size. One commonly used effect size measure for ANOVA is eta-squared (η²), which represents the proportion of variance in the dependent variable that can be explained by the group variable. The larger the value of η², the stronger the effect of the group variable on the dependent variable. \n",
    "\n",
    "You can calculate the effect size using the formula:\n",
    "\n",
    "η² = SS_between / SS_total\n",
    "\n",
    "where SS_between is the sum of squares between groups and SS_total is the total sum of squares. \n",
    "\n",
    "If the effect size is small (e.g., η² < 0.06), then the practical significance of the differences between the groups may be limited. However, if the effect size is large (e.g., η² > 0.14), then the differences between the groups are not only statistically significant but also practically important.\n",
    "\n",
    "In summary, the F-statistic and p-value indicate that there are significant differences between the groups, and the effect size provides further information about the practical significance of these differences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b7f6a7-130f-48db-8a5a-2e4e34a76cb5",
   "metadata": {},
   "source": [
    "### Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential consequences of using different methods to handle missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24505ea5-d945-4068-92f2-3c20ceca8147",
   "metadata": {},
   "source": [
    "Ans) In a repeated measures ANOVA, missing data can occur when a participant is unable or unwilling to provide data for one or more time points. Missing data can occur for various reasons, including equipment malfunction, subject dropout, and incomplete responses. Handling missing data is crucial for obtaining accurate results and minimizing bias in the analysis.\n",
    "\n",
    "One common approach to handling missing data in repeated measures ANOVA is to use a method called imputation. Imputation involves replacing missing values with plausible estimates based on other available data. Some commonly used imputation methods include mean imputation, last observation carried forward, and regression imputation.\n",
    "\n",
    "However, the choice of imputation method can have a significant impact on the results of the analysis. Different imputation methods can lead to different estimates of the mean, variance, and covariance of the variables. The choice of imputation method can also affect the standard errors and statistical significance of the results. Therefore, it is important to carefully consider the method of handling missing data and to compare the results of different methods to assess their impact on the conclusions of the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16afbfb-da2b-48a5-9ac7-80282857a03f",
   "metadata": {},
   "source": [
    "### Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide an example of a situation where a post-hoc test might be necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b15ca0c-8c63-4688-a258-d498ff41705f",
   "metadata": {},
   "source": [
    "Ans) Post-hoc tests are used after ANOVA to determine which groups are significantly different from each other when the overall F-test is significant. There are several post-hoc tests available, including Tukey's HSD (Honestly Significant Difference), Bonferroni correction, and Scheffe's test, among others.\n",
    "\n",
    "Tukey's HSD is a widely used post-hoc test and is often the default choice. It compares all possible pairs of means and determines the minimum significant difference that needs to be present between two means to conclude that they are different from each other.\n",
    "\n",
    "Bonferroni correction is a conservative post-hoc test that adjusts the significance level to account for multiple comparisons. It divides the original alpha level by the number of comparisons to control the family-wise error rate.\n",
    "\n",
    "Scheffe's test is a more conservative post-hoc test that controls for all possible comparisons simultaneously. It is often used when the number of groups is small or the sample sizes are unequal.\n",
    "\n",
    "An example of when a post-hoc test might be necessary is in a study comparing the effectiveness of three different medications for treating a specific condition. After conducting an ANOVA, if the overall F-test is significant, a post-hoc test can be used to determine which medications are significantly different from each other. For instance, Tukey's HSD could be used to compare all possible pairs of means and determine the minimum significant difference required to conclude that two means are different from each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70536d70-f60a-46cc-bc35-22393bebdaee",
   "metadata": {},
   "source": [
    "### Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from 50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python to determine if there are any significant differences between the mean weight loss of the three diets. Report the F-statistic and p-value, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5426e7e6-2c46-4bdb-8e69-d0481f3630cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 37.03885406173804\n",
      "p-value: 9.413909285242866e-14\n",
      "There is significant evidence of a difference in mean weight loss between the diets.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "# Generate some fake weight loss data for the three diets\n",
    "np.random.seed(123)\n",
    "diet_A = np.random.normal(loc=10, scale=2, size=50)\n",
    "diet_B = np.random.normal(loc=8, scale=2, size=50)\n",
    "diet_C = np.random.normal(loc=6, scale=2, size=50)\n",
    "\n",
    "# Conduct one-way ANOVA\n",
    "F, p = f_oneway(diet_A, diet_B, diet_C)\n",
    "\n",
    "# Report results\n",
    "print(\"F-statistic:\", F)\n",
    "print(\"p-value:\", p)\n",
    "if p < 0.05:\n",
    "    print(\"There is significant evidence of a difference in mean weight loss between the diets.\")\n",
    "else:\n",
    "    print(\"There is not significant evidence of a difference in mean weight loss between the diets.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6d8731-0994-4bcc-9bd5-52837341c441",
   "metadata": {},
   "source": [
    "In this example, we generate fake weight loss data for the three diets using normal distributions with different means (10, 8, and 6) and the same standard deviation of 2. We then use the f_oneway function to conduct the one-way ANOVA and obtain the F-statistic and p-value. Finally, we report the results and interpret them.\n",
    "\n",
    "Since the p-value is very small (less than 0.05), we reject the null hypothesis of equal mean weight loss between the diets and conclude that there is significant evidence of a difference in mean weight loss between the diets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6908976-42a6-41ae-a3ea-a1b99a2b5bbb",
   "metadata": {},
   "source": [
    "### Q10. A company wants to know if there are any significant differences in the average time it takes to complete a task using three different software programs: Program A, Program B, and Program C. They randomly assign 30 employees to one of the programs and record the time it takes each employee to complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or interaction effects between the software programs and employee experience level (novice vs. experienced). Report the F-statistics and p-values, and interpret the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85fe55d-562e-4513-ba4e-e1bafab4be60",
   "metadata": {},
   "source": [
    "Ans) To conduct a two-way ANOVA using Python, we can use the `ols` function from the `statsmodels` module. Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf0f2eff-7855-47c0-9843-58b8d5aaae37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            df      sum_sq   mean_sq         F    PR(>F)\n",
      "C(Program)                 2.0    2.926855  1.463428  0.264784  0.768009\n",
      "C(Experience)              1.0    3.094719  3.094719  0.559941  0.456374\n",
      "C(Program):C(Experience)   2.0    3.334259  1.667130  0.301641  0.740401\n",
      "Residual                  84.0  464.256575  5.526864       NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Generate some fake data for the task completion time\n",
    "np.random.seed(123)\n",
    "\n",
    "# Software programs\n",
    "programs = np.repeat(['A', 'B', 'C'], 30)\n",
    "\n",
    "# Employee experience levels\n",
    "experience = np.tile(['Novice', 'Experienced'], 45)\n",
    "\n",
    "# Task completion time\n",
    "time = np.random.normal(loc=10, scale=2, size=90)\n",
    "\n",
    "# Create a DataFrame\n",
    "data = pd.DataFrame({'Program': programs, 'Experience': experience, 'Time': time})\n",
    "\n",
    "# Conduct two-way ANOVA\n",
    "model = ols('Time ~ C(Program) + C(Experience) + C(Program):C(Experience)', data=data).fit()\n",
    "anova_table = sm.stats.anova_lm(model)\n",
    "\n",
    "# Report results\n",
    "print(anova_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e748581e-cb5b-47cf-9675-338b141c56e2",
   "metadata": {},
   "source": [
    "In this example, we generate fake data for the task completion time of 90 employees, with 30 employees assigned to each software program and an equal number of novice and experienced employees. We then create a DataFrame with the data and use the `ols` function to fit a two-way ANOVA model with the factors \"Program\" and \"Experience\" and their interaction term. The `anova_lm` function from `statsmodels` is used to obtain the ANOVA table, which includes the F-statistics and p-values.\n",
    "\n",
    "The output will display the ANOVA table with the F-statistics, degrees of freedom, sum of squares, mean squares, and p-values for each factor and interaction term. The p-values can be used to assess the significance of the main effects and interaction effects.\n",
    "\n",
    "From the ANOVA table, we can interpret the results as follows:\n",
    "\n",
    "- Program: The p-value for the \"Program\" factor is 0.768007, which is more than the significance level of 0.05. Therefore, we conclude that there is no evidence that the main effect of the software programs on the task completion time is significant.\n",
    "- Experience: The p-value for the \"Experience\" factor is 0.456374, which is greater than the significance level of 0.05. Therefore, we do not have sufficient evidence to conclude a significant main effect of employee experience level on the task completion time.\n",
    "- Program:Experience Interaction: The p-value for the interaction term \"Program:Experience\" is 0.740401, which is greater than the significance level of 0.05. Hence, we cannot conclude that there is a significant interaction effect between the software programs and employee experience level on the task completion time.\n",
    "\n",
    "In summary, based on the two-way ANOVA results, there is no significant main effect of the software programs and no significant interaction effect between the software programs and employee experience."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896d6050-85d3-4209-aed6-a35a7ef5d5c8",
   "metadata": {},
   "source": [
    "### Q11. An educational researcher is interested in whether a new teaching method improves student test scores. They randomly assign 100 students to either the control group (traditional teaching method) or the experimental group (new teaching method) and administer a test at the end of the semester. Conduct a two-sample t-test using Python to determine if there are any significant differences in test scores between the two groups. If the results are significant, follow up with a post-hoc test to determine which group(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0e9d70-754d-4dcf-8e92-79eca5393d69",
   "metadata": {},
   "source": [
    "Ans) To conduct a two-sample t-test and post-hoc test using Python, we can use the `scipy.stats` module. Here's an example:\n",
    "\n",
    "In this example, we generate fake data for test scores of 100 students, with 50 students in the control group (traditional teaching method) and 50 students in the experimental group (new teaching method). We use the `numpy.random.normal` function to generate normally distributed test scores for each group.\n",
    "\n",
    "We then use the `ttest_ind` function from `scipy.stats` to perform a two-sample t-test. The function takes the test scores of the control group and experimental group as inputs and returns the t-statistic and p-value.\n",
    "\n",
    "The output will display the t-statistic and p-value of the two-sample t-test.\n",
    "\n",
    "Since the p-value (0.0213) is less than the significance level of 0.05, we can conclude that there is a significant difference in test scores between the control group and the experimental group.\n",
    "\n",
    "To further analyze the differences between the groups, we can perform post-hoc tests. In this example, we used pairwise t-tests to compare the control group with the experimental group. The post-hoc test results indicate that the p-value for the comparison between the control and experimental groups is 0.0213, which confirms the significant difference between these two groups.\n",
    "\n",
    "Therefore, based on the two-sample t-test and post-hoc test, we can conclude that the new teaching method significantly improves student test scores compared to the traditional teaching method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9d69086-f2f8-4a8c-89bc-f43e98109ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-sample t-test results:\n",
      "t-statistic: -2.7585883908860698\n",
      "p-value: 0.006349134276947244\n",
      "\n",
      "Post-hoc test results:\n",
      "p-values for pairwise t-tests:\n",
      "Control vs Experimental: 0.006349676420454233\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Generate some fake data for test scores\n",
    "np.random.seed(123)\n",
    "\n",
    "control_scores = np.random.normal(loc=70, scale=10, size=100)\n",
    "experimental_scores = np.random.normal(loc=75, scale=12, size=100)\n",
    "\n",
    "# Perform two-sample t-test\n",
    "t_statistic, p_value = stats.ttest_ind(control_scores, experimental_scores)\n",
    "\n",
    "# Report results\n",
    "print(\"Two-sample t-test results:\")\n",
    "print(f\"t-statistic: {t_statistic}\")\n",
    "print(f\"p-value: {p_value}\")\n",
    "\n",
    "# Perform post-hoc test (pairwise t-tests)\n",
    "pairwise_ttests = stats.ttest_ind(control_scores, experimental_scores, equal_var=False)\n",
    "posthoc_p_values = pairwise_ttests.pvalue\n",
    "\n",
    "# Report post-hoc results\n",
    "print(\"\\nPost-hoc test results:\")\n",
    "print(\"p-values for pairwise t-tests:\")\n",
    "print(f\"Control vs Experimental: {posthoc_p_values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40d7257-a2cd-462f-beb4-8bc135c8f6b8",
   "metadata": {},
   "source": [
    "In this example, we generate fake data for test scores of 100 students, with 50 students in the control group (traditional teaching method) and 50 students in the experimental group (new teaching method). We use the `numpy.random.normal` function to generate normally distributed test scores for each group.\n",
    "\n",
    "We then use the `ttest_ind` function from `scipy.stats` to perform a two-sample t-test. The function takes the test scores of the control group and experimental group as inputs and returns the t-statistic and p-value.\n",
    "\n",
    "The output will display the t-statistic and p-value of the two-sample t-test.\n",
    "\n",
    "Since the p-value (0.0063) is less than the significance level of 0.05, we can conclude that there is a significant difference in test scores between the control group and the experimental group.\n",
    "\n",
    "To further analyze the differences between the groups, we performed post-hoc tests. In this example, we used pairwise t-tests to compare the control group with the experimental group. The post-hoc test results indicate that the p-value for the comparison between the control and experimental groups is 0.0063, which confirms the significant difference between these two groups.\n",
    "\n",
    "Therefore, based on the two-sample t-test and post-hoc test, we can conclude that the new teaching method significantly improves student test scores compared to the traditional teaching method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b9f788-9393-4ac3-a6d9-0e6f80704a96",
   "metadata": {},
   "source": [
    "### Q12. A researcher wants to know if there are any significant differences in the average daily sales of three retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store on those days. Conduct a repeated measures ANOVA using Python to determine if there are any significant differences in sales between the three stores. If the results are significant, follow up with a post-hoc test to determine which store(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b98397-a091-48d7-bf43-4c9aa1546606",
   "metadata": {},
   "source": [
    "Ans) To conduct a repeated measures ANOVA and post-hoc test using Python, we can use the `statsmodels` library. Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc3e5372-69a5-4c3c-8006-abd094722ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeated measures ANOVA results:\n",
      "            df        sum_sq       mean_sq         F    PR(>F)\n",
      "Store      2.0  1.204407e+05  60220.353984  3.639995  0.030328\n",
      "Residual  87.0  1.439335e+06  16544.076803       NaN       NaN\n",
      "\n",
      "Post-hoc test results:\n",
      " Multiple Comparison of Means - Tukey HSD, FWER=0.05  \n",
      "======================================================\n",
      "group1 group2 meandiff p-adj   lower    upper   reject\n",
      "------------------------------------------------------\n",
      "     A      B  62.5068   0.15  -16.683 141.6966  False\n",
      "     A      C  86.8565 0.0281   7.6667 166.0463   True\n",
      "     B      C  24.3497 0.7445 -54.8401 103.5395  False\n",
      "------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Generate some fake data for daily sales\n",
    "np.random.seed(123)\n",
    "\n",
    "store_a_sales = np.random.normal(loc=500, scale=100, size=30)\n",
    "store_b_sales = np.random.normal(loc=550, scale=120, size=30)\n",
    "store_c_sales = np.random.normal(loc=600, scale=110, size=30)\n",
    "\n",
    "# Create a pandas DataFrame for the data\n",
    "data = pd.DataFrame({\n",
    "    'Store': np.repeat(['A', 'B', 'C'], 30),\n",
    "    'Sales': np.concatenate([store_a_sales, store_b_sales, store_c_sales])\n",
    "})\n",
    "\n",
    "# Perform repeated measures ANOVA\n",
    "model = ols('Sales ~ Store', data=data).fit()\n",
    "anova_table = sm.stats.anova_lm(model)\n",
    "\n",
    "# Report results\n",
    "print(\"Repeated measures ANOVA results:\")\n",
    "print(anova_table)\n",
    "\n",
    "# Perform post-hoc test (Tukey's HSD)\n",
    "posthoc_results = sm.stats.multicomp.pairwise_tukeyhsd(data['Sales'], data['Store'])\n",
    "\n",
    "# Report post-hoc results\n",
    "print(\"\\nPost-hoc test results:\")\n",
    "print(posthoc_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18038ccf-04df-4bdd-93e5-7cf7c56b3aef",
   "metadata": {},
   "source": [
    "In this example, we generate fake data for daily sales of three retail stores: Store A, Store B, and Store C. We use the `numpy.random.normal` function to generate normally distributed sales values for each store.\n",
    "\n",
    "We then created a pandas DataFrame to store the data, with columns for \"Store\" and \"Sales\". Each row represents the sales of a particular store on a specific day.\n",
    "\n",
    "We use the `statsmodels` library to perform a repeated measures ANOVA. We specify the formula \"Sales ~ Store\" to indicate that we want to analyze the sales variable based on the store factor. The `ols` function is used to fit the ANOVA model, and the `anova_lm` function is used to generate the ANOVA table.\n",
    "\n",
    "The output will display the ANOVA table, which includes the F-statistic, p-value, and other relevant statistics.\n",
    "\n",
    "Since the p-value (0.03) is more than the significance level of 0.05, we can conclude that there is no evidence that the difference in average daily sales between the three stores is significant."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
